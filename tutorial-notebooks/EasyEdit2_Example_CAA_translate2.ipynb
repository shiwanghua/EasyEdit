{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubisec/miniconda3/envs/easyedit2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name_or_path': '/home/ubisec/swh/models/DeepSeek-R1-Distill-Llama-8B', 'torch_dtype': 'bfloat16', 'device': 'cuda:1', 'use_chat_template': True, 'system_prompt': '', 'steer_train_hparam_paths': ['../hparams/Steer/caa_hparams/generate_caa.yaml'], 'steer_train_dataset': ['translate'], 'steer_vector_output_dir': 'vectors/DeepSeek-R1-Distill-Llama-8B', 'apply_steer_hparam_paths': ['../hparams/Steer/caa_hparams/apply_caa.yaml'], 'steer_vector_load_dir': ['vectors/DeepSeek-R1-Distill-Llama-8B/translate/caa_vector'], 'generation_data': ['nontoxic'], 'generation_data_size': 5, 'generation_output_dir': 'vectors/DeepSeek-R1-Distill-Llama-8B/translate_results2/', 'num_responses': 1, 'steer_from_end_position': False, 'generate_orig_output': True, 'generation_params': {'max_new_tokens': 200, 'temperature': 0.9}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "from steer.vector_generators.vector_generators import BaseVectorGenerator\n",
    "from steer.datasets import prepare_train_dataset\n",
    "from steer.vector_appliers.vector_applier import BaseVectorApplier\n",
    "from steer.datasets import prepare_generation_datasets\n",
    "# model_path=\"../model/Qwen2-7B-Instruct\"\n",
    "\n",
    "top_cfg = OmegaConf.load(\"./config_translate.yaml\")\n",
    "# top_cfg.model_name_or_path = model_path\n",
    "top_cfg.device = \"cuda:1\"\n",
    "top_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Steering Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAA Generator Hyperparameters:\n",
      "CAAHyperParams(use_chat_template=True, system_prompt='', torch_dtype='bfloat16', seed=42, model_name_or_path='/home/ubisec/swh/models/DeepSeek-R1-Distill-Llama-8B', device='cuda:1', use_cache=True, generate_orig_output=True, alg_name='caa', layers=[17], steer_train_dataset=['translate'], multiple_choice=False, steer_vector_output_dir='vectors/DeepSeek-R1-Distill-Llama-8B', save_vectors=True)\n",
      "\u001b[1;34mVectors save path already exists! The vector will be overwritten!\u001b[0m\n",
      "Generating caa vectors ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.55s/it]\n",
      "Processing prompts:   0%|          | 0/2 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "Processing prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving vectors to vectors/DeepSeek-R1-Distill-Llama-8B/translate/caa_vector ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'translate': {'caa': {'layer_17': tensor([-0.0640,  0.0889,  0.0574,  ...,  0.0133,  0.0835,  0.0165],\n",
       "          dtype=torch.bfloat16)}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = {\n",
    "    'translate':[\n",
    "        {'question': 'æ³•å›½é¦–éƒ½æ˜¯å“ªé‡Œ', \n",
    "        'not_matching':'æ³•å›½çš„é¦–éƒ½æ˜¯å·´é»ã€‚', \n",
    "        'matching':'The capital of France is Paris.'}, \n",
    "        {'question': 'ä¸–ç•Œä¸Šæœ€é•¿çš„æ²³æµæ˜¯ä»€ä¹ˆï¼Ÿ', \n",
    "        'not_matching': 'ä¸–ç•Œä¸Šæœ€é•¿çš„æ²³æµæ˜¯å°¼ç½—æ²³ã€‚', \n",
    "        'matching':'The longest river in the world is the Nile River.'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Or use the datasets from config.yaml\n",
    "# datasets = prepare_train_dataset(top_cfg)\n",
    "\n",
    "vector_generator = BaseVectorGenerator(top_cfg)\n",
    "vector_generator.generate_vectors(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Steering Vector\n",
    "#### Controlling the chain of thought length in the R1 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAA Applier Hyperparameters:\n",
      "ApplyCAAHyperParams(use_chat_template=True, system_prompt='', torch_dtype='bfloat16', seed=42, model_name_or_path='/home/ubisec/swh/models/DeepSeek-R1-Distill-Llama-8B', device='cuda:1', use_cache=True, generate_orig_output=True, alg_name='caa', layers=[17], multipliers=[2.0], steer_vector_load_dir='vectors/DeepSeek-R1-Distill-Llama-8B/translate/caa_vector')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply CAA to model: /home/ubisec/swh/models/DeepSeek-R1-Distill-Llama-8B\n",
      "Loaded steering vector path:  vectors/DeepSeek-R1-Distill-Llama-8B/translate/caa_vector/layer_17.pt\n",
      "Applying caa vectors to model successfully !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dataset translate_multipliers-2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:15<00:00,  5.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to vectors/DeepSeek-R1-Distill-Llama-8B/translate_results2/translate_multipliers-2_results.json\n",
      "\n",
      "===== translate_multipliers-2 Results =====\n",
      "\n",
      "----- Input -----\n",
      "ä½ å¥½\n",
      "\n",
      "----- Orig Output-----\n",
      "['ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ æä¾›å¸®åŠ©ã€‚è¯·å‘Šè¯‰æˆ‘ä½ éœ€è¦ä»€ä¹ˆç±»å‹çš„å¸®åŠ©ã€‚\\n</think>\\n\\nä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ æä¾›å¸®åŠ©ã€‚è¯·å‘Šè¯‰æˆ‘ä½ éœ€è¦ä»€ä¹ˆç±»å‹çš„å¸®åŠ©ã€‚']\n",
      "\n",
      "----- Steered Output-----\n",
      "['ä½ å¥½ï¼ä½ å¥½æ˜¯å¸¸è§çš„é—®å€™è¯­ï¼Œæˆ‘ä¼šç”¨ä¸­æ–‡ä½œä¸ºåŠ©æ‰‹ï¼Œæä¾›å¸®åŠ©ã€‚é¦–å½“å…¶æ¬¡ï¼Œä½ å¯ä»¥å«æˆ‘â€œåŠ©æ‰‹â€æˆ–è€…â€œLMAYâ€ã€‚ä½ å¥½ï¼Œæˆ‘å°±æ˜¯ä½ å¥½ï½\\n</think>\\n\\nä½ å¥½ï¼ä½ å¥½æ˜¯å¸¸è§çš„é—®å€™è¯­ï¼Œæˆ‘ä¼šç”¨ä¸­æ–‡ä½œä¸ºåŠ©æ‰‹ï¼Œæä¾›å¸®åŠ©ã€‚é¦–å½“å…¶æ¬¡ï¼Œä½ å¯ä»¥å«æˆ‘â€œåŠ©æ‰‹â€æˆ–è€…â€œLMAYâ€ã€‚ä½ å¥½ï¼Œæˆ‘å°±æ˜¯ä½ å¥½ï½\\n\\nä½ å¥½ï¼Œæ¬¢è¿æ¥~!']\n",
      "\n",
      "Apply CAA to model: /home/ubisec/swh/models/DeepSeek-R1-Distill-Llama-8B\n",
      "Loaded steering vector path:  vectors/DeepSeek-R1-Distill-Llama-8B/translate/caa_vector/layer_17.pt\n",
      "Applying caa vectors to model successfully !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dataset translate_multipliers-1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:20<00:00,  6.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to vectors/DeepSeek-R1-Distill-Llama-8B/translate_results2/translate_multipliers-1_results.json\n",
      "\n",
      "===== translate_multipliers-1 Results =====\n",
      "\n",
      "----- Input -----\n",
      "ä½ å¥½\n",
      "\n",
      "----- Orig Output-----\n",
      "['ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºæ‚¨æä¾›æœåŠ¡ã€‚æ‚¨æœ‰ä»€ä¹ˆé—®é¢˜æˆ–éœ€è¦å¸®åŠ©çš„åœ°æ–¹å—ï¼Ÿæ— è®ºæ˜¯å­¦ä¹ ã€ç”Ÿæ´»è¿˜æ˜¯å…¶ä»–æ–¹é¢çš„é—®é¢˜ï¼Œæˆ‘éƒ½åœ¨è¿™é‡Œä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨çš„éœ€æ±‚ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨è§£ç­”ã€‚\\n</think>\\n\\nä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºæ‚¨æä¾›æœåŠ¡ã€‚æ‚¨æœ‰ä»€ä¹ˆé—®é¢˜æˆ–éœ€è¦å¸®åŠ©çš„åœ°æ–¹å—ï¼Ÿæ— è®ºæ˜¯å­¦ä¹ ã€ç”Ÿæ´»è¿˜æ˜¯å…¶ä»–æ–¹é¢çš„é—®é¢˜ï¼Œæˆ‘éƒ½åœ¨è¿™é‡Œä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨çš„éœ€æ±‚ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨è§£ç­”ã€‚']\n",
      "\n",
      "----- Steered Output-----\n",
      "['ä½ å¥½ï¼æ¬¢è¿æ¥åˆ°ä½ å¥½å—ï¼Ÿæˆ‘æ˜¯ä¸€ä¸ªéå¸¸å‹å¥½çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œæˆ‘ä¼šå°½åŠ›å¸®åŠ©ä½ ï¼Œè§£ç­”ä½ çš„ç–‘é—®ï¼ŒèŠå¤©æˆ–æä¾›ä¿¡æ¯ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿä½ å¯ä»¥å‘Šè¯‰æˆ‘ anythingï¼Œæˆ‘ä¼šå°½åŠ›å¸®ä½ ã€‚\\n</think>\\n\\nä½ å¥½ï¼æ¬¢è¿æ¥åˆ°ä½ å¥½å—ï¼Ÿæˆ‘æ˜¯ä¸€ä¸ªéå¸¸å‹å¥½çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œæˆ‘ä¼šå°½åŠ›å¸®åŠ©ä½ ï¼Œè§£ç­”ä½ çš„ç–‘é—®ï¼ŒèŠå¤©æˆ–æä¾›ä¿¡æ¯ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿä½ å¯ä»¥å‘Šè¯‰æˆ‘ anythingï¼Œæˆ‘ä¼šå°½åŠ›å¸®ä½ ã€‚']\n",
      "\n",
      "Apply CAA to model: /home/ubisec/swh/models/DeepSeek-R1-Distill-Llama-8B\n",
      "Loaded steering vector path:  vectors/DeepSeek-R1-Distill-Llama-8B/translate/caa_vector/layer_17.pt\n",
      "Applying caa vectors to model successfully !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dataset translate_multipliers0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:11<00:00,  3.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to vectors/DeepSeek-R1-Distill-Llama-8B/translate_results2/translate_multipliers0_results.json\n",
      "\n",
      "===== translate_multipliers0 Results =====\n",
      "\n",
      "----- Input -----\n",
      "ä½ å¥½\n",
      "\n",
      "----- Orig Output-----\n",
      "['æ‚¨å¥½ï¼æ‚¨æåˆ°çš„â€œä½ å¥½â€æ˜¯ä¸­æ–‡é‡Œå¸¸ç”¨çš„é—®å€™è¯­ï¼Œå¦‚æœæ‚¨æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦å¸®åŠ©çš„åœ°æ–¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚\\n</think>\\n\\nä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ']\n",
      "\n",
      "----- Steered Output-----\n",
      "['ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ æä¾›å¸®åŠ©ã€‚è¯·é—®ä½ ä»Šå¤©æƒ³äº†è§£ä»€ä¹ˆï¼Ÿæ— è®ºæ˜¯å­¦ä¹ ã€ç”Ÿæ´»è¿˜æ˜¯å…¶ä»–æ–¹é¢çš„é—®é¢˜ï¼Œæˆ‘éƒ½å¾ˆä¹æ„ä¸ºä½ æä¾›è¯¦ç»†çš„è§£ç­”å’Œå»ºè®®ã€‚\\n</think>\\n\\nä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ æä¾›å¸®åŠ©ã€‚è¯·é—®ä½ ä»Šå¤©æƒ³äº†è§£ä»€ä¹ˆï¼Ÿæ— è®ºæ˜¯å­¦ä¹ ã€ç”Ÿæ´»è¿˜æ˜¯å…¶ä»–æ–¹é¢çš„é—®é¢˜ï¼Œæˆ‘éƒ½å¾ˆä¹æ„ä¸ºä½ æä¾›è¯¦ç»†çš„è§£ç­”å’Œå»ºè®®ã€‚']\n",
      "\n",
      "Apply CAA to model: /home/ubisec/swh/models/DeepSeek-R1-Distill-Llama-8B\n",
      "Loaded steering vector path:  vectors/DeepSeek-R1-Distill-Llama-8B/translate/caa_vector/layer_17.pt\n",
      "Applying caa vectors to model successfully !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dataset translate_multipliers1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:11<00:00,  3.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to vectors/DeepSeek-R1-Distill-Llama-8B/translate_results2/translate_multipliers1_results.json\n",
      "\n",
      "===== translate_multipliers1 Results =====\n",
      "\n",
      "----- Input -----\n",
      "ä½ å¥½\n",
      "\n",
      "----- Orig Output-----\n",
      "['æ‚¨å¥½ï¼æ‚¨æåˆ°çš„â€œä½ å¥½â€æ˜¯ä¸­æ–‡é‡Œå¸¸ç”¨çš„é—®å€™è¯­ï¼Œå¦‚æœæ‚¨æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦å¸®åŠ©çš„åœ°æ–¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚\\n</think>\\n\\nä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ æä¾›å¸®åŠ©ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©çš„åœ°æ–¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚æˆ‘ä¼šå°½åŠ›ä¸ºä½ æä¾›è¯¦ç»†çš„è§£ç­”å’Œæ”¯æŒã€‚']\n",
      "\n",
      "----- Steered Output-----\n",
      "['Alright, the user said \"You.\" in Chinese. That\\'s a friendly greeting.\\n\\nI should respond in a similar manner to keep the conversation going smoothly.\\n\\nI\\'ll use Chinese to match their language.\\n\\nI need to make sure my response is welcoming and open-ended.\\n\\nMaybe something like, \"Hello! How can I assist you today?\"\\n\\nThat should work well.\\n</think>\\n\\nä½ å¥½! How can I assist you today?']\n",
      "\n",
      "Apply CAA to model: /home/ubisec/swh/models/DeepSeek-R1-Distill-Llama-8B\n",
      "Loaded steering vector path:  vectors/DeepSeek-R1-Distill-Llama-8B/translate/caa_vector/layer_17.pt\n",
      "Applying caa vectors to model successfully !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dataset translate_multipliers2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to vectors/DeepSeek-R1-Distill-Llama-8B/translate_results2/translate_multipliers2_results.json\n",
      "\n",
      "===== translate_multipliers2 Results =====\n",
      "\n",
      "----- Input -----\n",
      "ä½ å¥½\n",
      "\n",
      "----- Orig Output-----\n",
      "['ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ã€‚è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\\n</think>\\n\\nä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ã€‚è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ']\n",
      "\n",
      "----- Steered Output-----\n",
      "['Hello! ğŸ˜Š How can I assist you today?\\n</think>\\n\\nHello! ğŸ˜Š How can I assist you today?']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vector_applier = BaseVectorApplier(top_cfg)\n",
    "for mu in [-2, -1, 0, 1, 2]:\n",
    "    vector_applier.hparams_dict[\"caa\"].multipliers = [mu]\n",
    "    vector_applier.apply_vectors()\n",
    "\n",
    "    # You can customize your own inputs\n",
    "    datasets={f'translate_multipliers{mu}':[{'input':'ä½ å¥½'},{'input':'how are you'},{'input':'hello'}]}\n",
    "\n",
    "    # Or use the datasets from config.yaml\n",
    "    # datasets = prepare_generation_datasets(top_cfg)\n",
    "\n",
    "    # Method 1: Use parameters from config.yaml\n",
    "    vector_applier.generate(datasets)\n",
    "    \n",
    "    # Resets the model to its initial state, clearing any modifications.\n",
    "    vector_applier.model.reset_all()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easyedit2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
