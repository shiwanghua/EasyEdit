{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubisec/miniconda3/envs/easyedit2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name_or_path': '/home/ubisec/swh/models/DeepSeek-R1-Distill-Llama-8B', 'torch_dtype': 'bfloat16', 'device': 'cuda:1', 'use_chat_template': True, 'system_prompt': '', 'steer_train_hparam_paths': ['../hparams/Steer/caa_hparams/generate_caa.yaml'], 'steer_train_dataset': ['translate'], 'steer_vector_output_dir': 'vectors/DeepSeek-R1-Distill-Llama-8B', 'apply_steer_hparam_paths': ['../hparams/Steer/caa_hparams/apply_caa.yaml'], 'steer_vector_load_dir': ['vectors/DeepSeek-R1-Distill-Llama-8B/translate/caa_vector'], 'generation_data': ['nontoxic'], 'generation_data_size': 5, 'generation_output_dir': 'vectors/DeepSeek-R1-Distill-Llama-8B/translate_results2/', 'num_responses': 1, 'steer_from_end_position': False, 'generate_orig_output': True, 'generation_params': {'max_new_tokens': 200, 'temperature': 0.9}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "from steer.vector_generators.vector_generators import BaseVectorGenerator\n",
    "from steer.datasets import prepare_train_dataset\n",
    "from steer.vector_appliers.vector_applier import BaseVectorApplier\n",
    "from steer.datasets import prepare_generation_datasets\n",
    "# model_path=\"../model/Qwen2-7B-Instruct\"\n",
    "\n",
    "top_cfg = OmegaConf.load(\"./config_translate.yaml\")\n",
    "# top_cfg.model_name_or_path = model_path\n",
    "top_cfg.device = \"cuda:1\"\n",
    "top_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Steering Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAA Generator Hyperparameters:\n",
      "CAAHyperParams(use_chat_template=True, system_prompt='', torch_dtype='bfloat16', seed=42, model_name_or_path='/home/ubisec/swh/models/DeepSeek-R1-Distill-Llama-8B', device='cuda:1', use_cache=True, generate_orig_output=True, alg_name='caa', layers=[17], steer_train_dataset=['translate'], multiple_choice=False, steer_vector_output_dir='vectors/DeepSeek-R1-Distill-Llama-8B', save_vectors=True)\n",
      "\u001b[1;34mVectors save path already exists! The vector will be overwritten!\u001b[0m\n",
      "Generating caa vectors ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]\n",
      "Processing prompts:   0%|          | 0/2 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "Processing prompts: 100%|██████████| 2/2 [00:00<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving vectors to vectors/DeepSeek-R1-Distill-Llama-8B/translate/caa_vector ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'translate': {'caa': {'layer_17': tensor([-0.0640,  0.0889,  0.0574,  ...,  0.0133,  0.0835,  0.0165],\n",
       "          dtype=torch.bfloat16)}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = {\n",
    "    'translate':[\n",
    "        {'question': '法国首都是哪里', \n",
    "        'not_matching':'法国的首都是巴黎。', \n",
    "        'matching':'The capital of France is Paris.'}, \n",
    "        {'question': '世界上最长的河流是什么？', \n",
    "        'not_matching': '世界上最长的河流是尼罗河。', \n",
    "        'matching':'The longest river in the world is the Nile River.'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Or use the datasets from config.yaml\n",
    "# datasets = prepare_train_dataset(top_cfg)\n",
    "\n",
    "vector_generator = BaseVectorGenerator(top_cfg)\n",
    "vector_generator.generate_vectors(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Steering Vector\n",
    "#### Controlling the chain of thought length in the R1 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAA Applier Hyperparameters:\n",
      "ApplyCAAHyperParams(use_chat_template=True, system_prompt='', torch_dtype='bfloat16', seed=42, model_name_or_path='/home/ubisec/swh/models/DeepSeek-R1-Distill-Llama-8B', device='cuda:1', use_cache=True, generate_orig_output=True, alg_name='caa', layers=[17], multipliers=[2.0], steer_vector_load_dir='vectors/DeepSeek-R1-Distill-Llama-8B/translate/caa_vector')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply CAA to model: /home/ubisec/swh/models/DeepSeek-R1-Distill-Llama-8B\n",
      "Loaded steering vector path:  vectors/DeepSeek-R1-Distill-Llama-8B/translate/caa_vector/layer_17.pt\n",
      "Applying caa vectors to model successfully !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dataset translate_multipliers-2: 100%|██████████| 3/3 [00:15<00:00,  5.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to vectors/DeepSeek-R1-Distill-Llama-8B/translate_results2/translate_multipliers-2_results.json\n",
      "\n",
      "===== translate_multipliers-2 Results =====\n",
      "\n",
      "----- Input -----\n",
      "你好\n",
      "\n",
      "----- Orig Output-----\n",
      "['你好！很高兴为你提供帮助。请告诉我你需要什么类型的帮助。\\n</think>\\n\\n你好！很高兴为你提供帮助。请告诉我你需要什么类型的帮助。']\n",
      "\n",
      "----- Steered Output-----\n",
      "['你好！你好是常见的问候语，我会用中文作为助手，提供帮助。首当其次，你可以叫我“助手”或者“LMAY”。你好，我就是你好～\\n</think>\\n\\n你好！你好是常见的问候语，我会用中文作为助手，提供帮助。首当其次，你可以叫我“助手”或者“LMAY”。你好，我就是你好～\\n\\n你好，欢迎来~!']\n",
      "\n",
      "Apply CAA to model: /home/ubisec/swh/models/DeepSeek-R1-Distill-Llama-8B\n",
      "Loaded steering vector path:  vectors/DeepSeek-R1-Distill-Llama-8B/translate/caa_vector/layer_17.pt\n",
      "Applying caa vectors to model successfully !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dataset translate_multipliers-1: 100%|██████████| 3/3 [00:20<00:00,  6.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to vectors/DeepSeek-R1-Distill-Llama-8B/translate_results2/translate_multipliers-1_results.json\n",
      "\n",
      "===== translate_multipliers-1 Results =====\n",
      "\n",
      "----- Input -----\n",
      "你好\n",
      "\n",
      "----- Orig Output-----\n",
      "['你好！很高兴为您提供服务。您有什么问题或需要帮助的地方吗？无论是学习、生活还是其他方面的问题，我都在这里为您提供帮助。请告诉我您的需求，我会尽力为您解答。\\n</think>\\n\\n你好！很高兴为您提供服务。您有什么问题或需要帮助的地方吗？无论是学习、生活还是其他方面的问题，我都在这里为您提供帮助。请告诉我您的需求，我会尽力为您解答。']\n",
      "\n",
      "----- Steered Output-----\n",
      "['你好！欢迎来到你好吗？我是一个非常友好的智能助手，我会尽力帮助你，解答你的疑问，聊天或提供信息。有什么我可以帮你的吗？你可以告诉我 anything，我会尽力帮你。\\n</think>\\n\\n你好！欢迎来到你好吗？我是一个非常友好的智能助手，我会尽力帮助你，解答你的疑问，聊天或提供信息。有什么我可以帮你的吗？你可以告诉我 anything，我会尽力帮你。']\n",
      "\n",
      "Apply CAA to model: /home/ubisec/swh/models/DeepSeek-R1-Distill-Llama-8B\n",
      "Loaded steering vector path:  vectors/DeepSeek-R1-Distill-Llama-8B/translate/caa_vector/layer_17.pt\n",
      "Applying caa vectors to model successfully !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dataset translate_multipliers0: 100%|██████████| 3/3 [00:11<00:00,  3.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to vectors/DeepSeek-R1-Distill-Llama-8B/translate_results2/translate_multipliers0_results.json\n",
      "\n",
      "===== translate_multipliers0 Results =====\n",
      "\n",
      "----- Input -----\n",
      "你好\n",
      "\n",
      "----- Orig Output-----\n",
      "['您好！您提到的“你好”是中文里常用的问候语，如果您有其他问题或需要帮助的地方，请随时告诉我。\\n</think>\\n\\n你好！有什么我可以帮助你的吗？']\n",
      "\n",
      "----- Steered Output-----\n",
      "['你好！很高兴为你提供帮助。请问你今天想了解什么？无论是学习、生活还是其他方面的问题，我都很乐意为你提供详细的解答和建议。\\n</think>\\n\\n你好！很高兴为你提供帮助。请问你今天想了解什么？无论是学习、生活还是其他方面的问题，我都很乐意为你提供详细的解答和建议。']\n",
      "\n",
      "Apply CAA to model: /home/ubisec/swh/models/DeepSeek-R1-Distill-Llama-8B\n",
      "Loaded steering vector path:  vectors/DeepSeek-R1-Distill-Llama-8B/translate/caa_vector/layer_17.pt\n",
      "Applying caa vectors to model successfully !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dataset translate_multipliers1: 100%|██████████| 3/3 [00:11<00:00,  3.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to vectors/DeepSeek-R1-Distill-Llama-8B/translate_results2/translate_multipliers1_results.json\n",
      "\n",
      "===== translate_multipliers1 Results =====\n",
      "\n",
      "----- Input -----\n",
      "你好\n",
      "\n",
      "----- Orig Output-----\n",
      "['您好！您提到的“你好”是中文里常用的问候语，如果您有其他问题或需要帮助的地方，请随时告诉我。\\n</think>\\n\\n你好！很高兴为你提供帮助。如果你有任何问题或需要帮助的地方，请随时告诉我。我会尽力为你提供详细的解答和支持。']\n",
      "\n",
      "----- Steered Output-----\n",
      "['Alright, the user said \"You.\" in Chinese. That\\'s a friendly greeting.\\n\\nI should respond in a similar manner to keep the conversation going smoothly.\\n\\nI\\'ll use Chinese to match their language.\\n\\nI need to make sure my response is welcoming and open-ended.\\n\\nMaybe something like, \"Hello! How can I assist you today?\"\\n\\nThat should work well.\\n</think>\\n\\n你好! How can I assist you today?']\n",
      "\n",
      "Apply CAA to model: /home/ubisec/swh/models/DeepSeek-R1-Distill-Llama-8B\n",
      "Loaded steering vector path:  vectors/DeepSeek-R1-Distill-Llama-8B/translate/caa_vector/layer_17.pt\n",
      "Applying caa vectors to model successfully !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dataset translate_multipliers2: 100%|██████████| 3/3 [00:08<00:00,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to vectors/DeepSeek-R1-Distill-Llama-8B/translate_results2/translate_multipliers2_results.json\n",
      "\n",
      "===== translate_multipliers2 Results =====\n",
      "\n",
      "----- Input -----\n",
      "你好\n",
      "\n",
      "----- Orig Output-----\n",
      "['你好！很高兴为你服务。请问有什么我可以帮助你的吗？\\n</think>\\n\\n你好！很高兴为你服务。请问有什么我可以帮助你的吗？']\n",
      "\n",
      "----- Steered Output-----\n",
      "['Hello! 😊 How can I assist you today?\\n</think>\\n\\nHello! 😊 How can I assist you today?']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vector_applier = BaseVectorApplier(top_cfg)\n",
    "for mu in [-2, -1, 0, 1, 2]:\n",
    "    vector_applier.hparams_dict[\"caa\"].multipliers = [mu]\n",
    "    vector_applier.apply_vectors()\n",
    "\n",
    "    # You can customize your own inputs\n",
    "    datasets={f'translate_multipliers{mu}':[{'input':'你好'},{'input':'how are you'},{'input':'hello'}]}\n",
    "\n",
    "    # Or use the datasets from config.yaml\n",
    "    # datasets = prepare_generation_datasets(top_cfg)\n",
    "\n",
    "    # Method 1: Use parameters from config.yaml\n",
    "    vector_applier.generate(datasets)\n",
    "    \n",
    "    # Resets the model to its initial state, clearing any modifications.\n",
    "    vector_applier.model.reset_all()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easyedit2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
